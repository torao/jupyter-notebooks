{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convnet 各層のフィルタ可視化、特徴強度画像作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "input_file = \"kawasemi.jpg\"\n",
    "outout_dir = \"filter-intensities\"\n",
    "model = VGG16(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.cm import get_cmap\n",
    "from keras.preprocessing import image\n",
    "\n",
    "cm = get_cmap(\"inferno\")\n",
    "\n",
    "def heatmap(activations):\n",
    "  \"\"\"活性化強度 (0.0-1.0) の画像をヒートマップ化し 0-255 の RGB 画像として扱えるように変換\"\"\"\n",
    "  return (cm(activations / np.max(activations)) * 255).astype(np.int8).transpose((0, 3, 1, 2, 4))[:, :, :, :, :3]\n",
    "\n",
    "def concat_images(images, spacing=1, space_color=0):\n",
    "  \"\"\"リスト化されている画像を縦横に並べた 1 枚の画像を作成する\"\"\"\n",
    "  n_images = len(images)\n",
    "  rows = math.ceil(math.sqrt(n_images))\n",
    "  cols = math.ceil(n_images / rows)\n",
    "  vstack = []\n",
    "  for y in range(cols):\n",
    "    size = min(rows, n_images - y * cols)\n",
    "    hstack = []\n",
    "    for x in range(rows):\n",
    "      if x is not 0:\n",
    "        hstack.append(np.full((images[x-1].shape[0], spacing, 3), space_color, dtype=np.uint8))\n",
    "      i = y * cols + x\n",
    "      if i < len(images):\n",
    "        hstack.append(images[i].astype(np.uint8))\n",
    "      else:\n",
    "        hstack.append(np.zeros(images[0].shape, dtype=np.uint8))\n",
    "    row = cv2.hconcat(hstack)\n",
    "    vstack.append(row)\n",
    "    if y + 1 < cols:\n",
    "      vstack.append(np.full((spacing, row.shape[1], 3), space_color, dtype=np.uint8))\n",
    "  return Image.fromarray(cv2.vconcat(vstack), \"RGB\")\n",
    "\n",
    "def deprocess_image(x):\n",
    "  # テンソルを正規化: 中心 0、標準偏差 0.1 に調整\n",
    "  x -= x.mean()\n",
    "  x /= (x.std() + 1e-5)\n",
    "  x *= 0.1\n",
    "\n",
    "  # [0,1] 範囲にクリッピング\n",
    "  x += 0.5\n",
    "  x = np.clip(x, 0, 1)\n",
    "\n",
    "  # RGB に変換\n",
    "  x *= 255\n",
    "  return np.clip(x, 0, 255).astype(np.uint8)\n",
    "\n",
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "  layer_output = model.get_layer(layer_name).output\n",
    "  loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "  grads = K.gradients(loss, model.input)[0]\n",
    "  grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "  iter = K.function([model.input], [loss, grads])\n",
    "  input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "  step = 1.\n",
    "  for i in range(40):\n",
    "    loss_value, grads_value = iter([input_img_data])\n",
    "    input_img_data += grads_value * step\n",
    "  img = input_img_data[0]\n",
    "  return deprocess_image(img)\n",
    "\n",
    "def visualize_activation(activations):\n",
    "  imgs = heatmap(activations)\n",
    "  return image.img_to_array(concat_images(imgs, space_color=0x20)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
